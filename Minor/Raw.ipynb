{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('myfile3.txt',delimiter='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Thread_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_Sent</th>\n",
       "      <th>Address</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ body:HDFCUPI 48PWqRHx1fPnBmoTQeZrNXBAj2xwl36...</td>\n",
       "      <td>thread_id:38</td>\n",
       "      <td>date:1511195729532</td>\n",
       "      <td>date_sent:0</td>\n",
       "      <td>address:+919289210101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body:Dear Customer, You have 2 missed calls...</td>\n",
       "      <td>thread_id:152</td>\n",
       "      <td>date:1511195566351</td>\n",
       "      <td>date_sent:1511195553000</td>\n",
       "      <td>address:+917986452922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body:4466218083398</td>\n",
       "      <td>thread_id:22</td>\n",
       "      <td>date:1511185904196</td>\n",
       "      <td>date_sent:0</td>\n",
       "      <td>address:09634224747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body:Haan</td>\n",
       "      <td>thread_id:68</td>\n",
       "      <td>date:1511172956752</td>\n",
       "      <td>date_sent:1511172960559</td>\n",
       "      <td>address:+918279925985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body:Attendance ho gyi?</td>\n",
       "      <td>thread_id:68</td>\n",
       "      <td>date:1511172156198</td>\n",
       "      <td>date_sent:1511172154000</td>\n",
       "      <td>address:+918279925985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body       Thread_Id  \\\n",
       "0  [ body:HDFCUPI 48PWqRHx1fPnBmoTQeZrNXBAj2xwl36...    thread_id:38   \n",
       "1     body:Dear Customer, You have 2 missed calls...   thread_id:152   \n",
       "2                                 body:4466218083398    thread_id:22   \n",
       "3                                          body:Haan    thread_id:68   \n",
       "4                            body:Attendance ho gyi?    thread_id:68   \n",
       "\n",
       "                  Date                 Date_Sent                 Address  \\\n",
       "0   date:1511195729532               date_sent:0   address:+919289210101   \n",
       "1   date:1511195566351   date_sent:1511195553000   address:+917986452922   \n",
       "2   date:1511185904196               date_sent:0     address:09634224747   \n",
       "3   date:1511172956752   date_sent:1511172960559   address:+918279925985   \n",
       "4   date:1511172156198   date_sent:1511172154000   address:+918279925985   \n",
       "\n",
       "  Unnamed: 5  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Thread_Id','Date','Date_Sent','Address','Unnamed: 5'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(cols):\n",
    "    return ' '.join(cols.split(':'))\n",
    "def func2(cols):\n",
    "    return ''.join([char for char in cols if char not in string.punctuation])\n",
    "def func3(cols):\n",
    "    return [word.lower() for word in cols.split() if word.lower() not in stopwords.words('English') and word.lower()!='body']\n",
    "    \n",
    "#df['Body'] = df['Body'].apply(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body'] = df['Body'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ body HDFCUPI 48PWqRHx1fPnBmoTQeZrNXBAj2xwl36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body Dear Customer, You have 2 missed calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body 4466218083398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body Haan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body Attendance ho gyi?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body\n",
       "0  [ body HDFCUPI 48PWqRHx1fPnBmoTQeZrNXBAj2xwl36...\n",
       "1     body Dear Customer, You have 2 missed calls...\n",
       "2                                 body 4466218083398\n",
       "3                                          body Haan\n",
       "4                            body Attendance ho gyi?"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'Message':'Body'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['Label'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Student, Its never too late-clear your ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join V-STUDY and score excellent marks in clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Join crash courses for B.ST,A/C'S,ECO,ENG,&amp;IP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRASH COURSES by BEST POOL OF FACULTY. ENGLISH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ola Shuttle user, get 60% Off on your nex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body\n",
       "0  Dear Student, Its never too late-clear your ba...\n",
       "1  Join V-STUDY and score excellent marks in clas...\n",
       "2  Join crash courses for B.ST,A/C'S,ECO,ENG,&IP ...\n",
       "3  CRASH COURSES by BEST POOL OF FACULTY. ENGLISH...\n",
       "4  Dear Ola Shuttle user, get 60% Off on your nex..."
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>SPOT ADMISSIONS FOR FORENSIC SCIENCE, Cardiac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>CBSE Private Exam 2018, Forms are starting for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>If you receive offer of lottery winnings or ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Gokul sent you a Blue Packet which expires in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>CBSE Private Exam 2018, Forms are starting for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body\n",
       "179  SPOT ADMISSIONS FOR FORENSIC SCIENCE, Cardiac ...\n",
       "180  CBSE Private Exam 2018, Forms are starting for...\n",
       "181  If you receive offer of lottery winnings or ch...\n",
       "182  Gokul sent you a Blue Packet which expires in ...\n",
       "183  CBSE Private Exam 2018, Forms are starting for..."
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body'] = df['Body'].apply(func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>SPOT ADMISSIONS FOR FORENSIC SCIENCE Cardiac C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>CBSE Private Exam 2018 Forms are starting for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>If you receive offer of lottery winnings or ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Gokul sent you a Blue Packet which expires in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>CBSE Private Exam 2018 Forms are starting for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body\n",
       "179  SPOT ADMISSIONS FOR FORENSIC SCIENCE Cardiac C...\n",
       "180  CBSE Private Exam 2018 Forms are starting for ...\n",
       "181  If you receive offer of lottery winnings or ch...\n",
       "182  Gokul sent you a Blue Packet which expires in ...\n",
       "183  CBSE Private Exam 2018 Forms are starting for ..."
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body'] = df['Body'].apply(func3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[spot, admissions, forensic, science, cardiac,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[cbse, private, exam, 2018, forms, starting, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[receive, offer, lottery, winnings, cheap, fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>[gokul, sent, blue, packet, expires, 59, mins,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>[cbse, private, exam, 2018, forms, starting, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body\n",
       "179  [spot, admissions, forensic, science, cardiac,...\n",
       "180  [cbse, private, exam, 2018, forms, starting, c...\n",
       "181  [receive, offer, lottery, winnings, cheap, fun...\n",
       "182  [gokul, sent, blue, packet, expires, 59, mins,...\n",
       "183  [cbse, private, exam, 2018, forms, starting, c..."
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = ['fashion','myntra','fbb','amazon','flipkart','clothes','gifts','festive','season','shopping','sale','offer','stores']\n",
    "food = ['food','offer','burgur','pizza','dominos','veg','snacks','desserts','recipie','cake','eat','homemade','cooked','delicious','taste']\n",
    "finance = ['money','finance','recharge','bank','account','inr','ruppee','balance','purchase','sale','transaction','credit','debit','deposit','property','sell','buy','market','invest','loan','bank','cash','rs']\n",
    "health = ['health','weight','blood','test','heart','kidney','hospital','medicine','disease','water','homeopathy','ayurvedic']\n",
    "travel = ['cabs','pool','uber','ola','ride','discount','share','city','travel','cab','train','book','ticket','order']\n",
    "telecom = ['telecom','recharge','bill','joi','vodafone','airtel','call','sms','customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = ['fashion','myntra','fbb','fashion','amazon','flipkart','clothes','gifts','festive','season','sale','jewellery','shopping','shop','voucher','offer','center']\n",
    "food = ['food','dominos','pizza','hut','cheese','medium','pizzahut','food','veg','groceries','burger','sandwhich','foodpanda','grofers','bazaar','milkshake','baker','cake','cookies']\n",
    "finance = ['finance','recharge','paytm','mobile','balance','bank','inr','debit','card','credit','acct','icici','hdfc','sbi','pnb','fixed','deposit','property','estate','sell','central','market','invest','investment','buy','lacs','emi','loan','investor']\n",
    "health = ['health','weight','blood','test','medicines','medicine','disease','loss','water','purifier','homeopathy','homeopathic','ayurvedic']\n",
    "#education = ['education','exam','education','college','quiz','tutorial','course','school','college','result']\n",
    "education = ['cabs','pool','uber','ola','ride','discount','uberGO','share','city','cab','PNR','book','pnr','booking','order']\n",
    "telecom = ['telecom','customer','airtel','jio','vodafone','idea','call','unlimited','balance','recharge']\n",
    "\n",
    "\n",
    "# Aur categories daalni hai.... please daal do achi achi categories isme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = [st.stem(word) for word in fashion]\n",
    "food = [st.stem(word) for word in food]\n",
    "finance = [st.stem(word) for word in finance]\n",
    "health = [st.stem(word) for word in health]\n",
    "travel = [st.stem(word) for word in travel]\n",
    "telecom = [st.stem(word) for word in telecom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['health',\n",
       " 'weight',\n",
       " 'blood',\n",
       " 'test',\n",
       " 'heart',\n",
       " 'kidney',\n",
       " 'hospit',\n",
       " 'medicin',\n",
       " 'diseas',\n",
       " 'water',\n",
       " 'homeopathi',\n",
       " 'ayurved']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_it(cols):\n",
    "    \n",
    "    fashion_count = 0\n",
    "    food_count = 0\n",
    "    finance_count = 0\n",
    "    health_count = 0\n",
    "    travel_count = 0\n",
    "    telecom_count = 0\n",
    "\n",
    "    \n",
    "    for word in cols:\n",
    "        word = word.lower()\n",
    "        word = st.stem(word)\n",
    "\n",
    "        #print(word)\n",
    "        if word in fashion:\n",
    "            fashion_count += 1\n",
    "        \n",
    "        if word in food:\n",
    "            food_count += 1\n",
    "        \n",
    "        if word in finance:\n",
    "            finance_count += 1  \n",
    "            \n",
    "        if word in health:\n",
    "            health_count += 1   \n",
    "            \n",
    "        if word in travel:\n",
    "            travel_count += 1\n",
    "            \n",
    "        if word in telecom:\n",
    "            telecom_count += 1\n",
    "            #print('Hello',finance_count)\n",
    "            \n",
    "    total = int(fashion_count + food_count + finance_count + health_count + travel_count + telecom_count)\n",
    "    \n",
    "    if total==0:\n",
    "        total = 1\n",
    "    \n",
    "    fashion_avg = float(fashion_count/total)\n",
    "    food_avg = float(food_count/total)\n",
    "    finance_avg = float(finance_count/total)\n",
    "    health_avg = float(health_count/total)    \n",
    "    travel_avg = float(travel_count/total)    \n",
    "    telecom_avg = float(telecom_count/total)\n",
    "    \n",
    "    \n",
    "    maxx = max(fashion_avg,food_avg,finance_avg,health_avg,travel_avg,telecom_avg)\n",
    "    if maxx==0:\n",
    "        return 'other'\n",
    "    elif maxx==fashion_avg:\n",
    "        return 'fashion'    \n",
    "    elif maxx==food_avg:\n",
    "        return 'food'\n",
    "    elif maxx==finance_avg:\n",
    "        return 'finance'\n",
    "    elif maxx==health_avg:\n",
    "        return 'health'\n",
    "    elif maxx==travel_avg:\n",
    "        return 'travel'\n",
    "    elif maxx==telecom_avg:\n",
    "        return 'telecom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['Body'].apply(label_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hdfcupi, 48pwqrhx1fpnbmotqezrnxbaj2xwl36v4tcg...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[dear, customer, 2, missed, calls, 91798645292...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4466218083398]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[haan]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[attendance, ho, gyi]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2843200343195]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5177178220357]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[dear, customer, 918279925985, available, take...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[invited, hike, sent, free, money, join, get, ...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[8860727024]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[4193328457651]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[invited, hike, sent, free, money, join, get, ...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[invited, hike, sent, free, money, join, get, ...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[dear, customer, missed, call, 919897740346, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[dear, customer, 2, missed, calls, 91989774034...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[https, youtubeilg3ggewq5u]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[dear, customer, 2, missed, calls, 91989774034...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1651648459490]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[upi, pg2ctmq2tclq3vrb5gvu1jpsukrkylijuhia9va]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[parimal, ka, bhej, de]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[dear, customer, 918279925985, available, take...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[dear, customer, missed, call, 919411151102, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[dear, customer, missed, call, 918057702328, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[dear, customer, missed, call, 918057702328, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[dear, customer, 2, missed, calls, 91941115110...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[dear, customer, 2, missed, calls, 91861960608...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[dear, customer, missed, call, 918800454404, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[dear, customer, missed, call, 919958936869, l...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[ek, baar, check, kar, lo, application, ki, so...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>[great, news, starting, crash, courses, acseng...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[great, news, starting, crash, courses, acseng...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>[join, crash, course, acsengbstip, eco, batche...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>[aaj, ho, rhi, hai, pdai]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>[acchi, wali]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>[lenskart, celebrates, 32, optical, stores, de...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[lenskarts, bestselling, air, collection, ligh...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>[invited, hike, join, 24, hours, get, rs, 51, ...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>[yadavayushmaan08gmailcom, bhej, ppt]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[free, dental, checkup, xray, family, dentist,...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>[invited, hike, join, 24, hours, get, rs, 51, ...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[pizza, hut, 50, dont, cook, wednesday, get, 5...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[get, unlimited, pan, pizzas, garlic, breadrs,...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[hey, loving, new, hike, awesome, stickers, op...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[spl, bcom, classes, renowned, faculties, tax,...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[pls, reach, email, mrchrisc1outlookcom, immed...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>[pls, reach, email, mrchrisc1outlookcom, immed...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>[pest, control, winter, offer, make, home, pes...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[thank, part, jio, family, stay, connected, la...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>[plan, jio, 8178390589, expires, today, servic...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>[join, crash, course, engbstip, ecoafter, exce...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>[pearl, academy, invites, launch, school, medi...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>[main, tests15, live, classes35, video, lectur...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>[personal, loan, lowest, rate, preclose, charg...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>[looking, get, great, score, rank, jeemain18, ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[spot, admissions, forensic, science, cardiac,...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[cbse, private, exam, 2018, forms, starting, c...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[receive, offer, lottery, winnings, cheap, fun...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>[gokul, sent, blue, packet, expires, 59, mins,...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>[cbse, private, exam, 2018, forms, starting, c...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7912 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body    Label\n",
       "0    [hdfcupi, 48pwqrhx1fpnbmotqezrnxbaj2xwl36v4tcg...    other\n",
       "1    [dear, customer, 2, missed, calls, 91798645292...  telecom\n",
       "2                                      [4466218083398]    other\n",
       "3                                               [haan]    other\n",
       "4                                [attendance, ho, gyi]    other\n",
       "5                                      [2843200343195]    other\n",
       "6                                      [5177178220357]    other\n",
       "7    [dear, customer, 918279925985, available, take...  telecom\n",
       "8    [invited, hike, sent, free, money, join, get, ...  finance\n",
       "9                                                   []    other\n",
       "10                                        [8860727024]    other\n",
       "11                                     [4193328457651]    other\n",
       "12   [invited, hike, sent, free, money, join, get, ...  finance\n",
       "13   [invited, hike, sent, free, money, join, get, ...  finance\n",
       "14   [dear, customer, missed, call, 919897740346, l...  telecom\n",
       "15   [dear, customer, 2, missed, calls, 91989774034...  telecom\n",
       "16                         [https, youtubeilg3ggewq5u]    other\n",
       "17   [dear, customer, 2, missed, calls, 91989774034...  telecom\n",
       "18                                     [1651648459490]    other\n",
       "19      [upi, pg2ctmq2tclq3vrb5gvu1jpsukrkylijuhia9va]    other\n",
       "20                             [parimal, ka, bhej, de]    other\n",
       "21   [dear, customer, 918279925985, available, take...  telecom\n",
       "22   [dear, customer, missed, call, 919411151102, l...  telecom\n",
       "23   [dear, customer, missed, call, 918057702328, l...  telecom\n",
       "24   [dear, customer, missed, call, 918057702328, l...  telecom\n",
       "25   [dear, customer, 2, missed, calls, 91941115110...  telecom\n",
       "26   [dear, customer, 2, missed, calls, 91861960608...  telecom\n",
       "27   [dear, customer, missed, call, 918800454404, l...  telecom\n",
       "28   [dear, customer, missed, call, 919958936869, l...  telecom\n",
       "29   [ek, baar, check, kar, lo, application, ki, so...    other\n",
       "..                                                 ...      ...\n",
       "154  [great, news, starting, crash, courses, acseng...    other\n",
       "155  [great, news, starting, crash, courses, acseng...    other\n",
       "156  [join, crash, course, acsengbstip, eco, batche...  telecom\n",
       "157                          [aaj, ho, rhi, hai, pdai]    other\n",
       "158                                      [acchi, wali]    other\n",
       "159  [lenskart, celebrates, 32, optical, stores, de...  fashion\n",
       "160  [lenskarts, bestselling, air, collection, ligh...  fashion\n",
       "161  [invited, hike, join, 24, hours, get, rs, 51, ...  finance\n",
       "162              [yadavayushmaan08gmailcom, bhej, ppt]    other\n",
       "163  [free, dental, checkup, xray, family, dentist,...  finance\n",
       "164  [invited, hike, join, 24, hours, get, rs, 51, ...  finance\n",
       "165  [pizza, hut, 50, dont, cook, wednesday, get, 5...     food\n",
       "166  [get, unlimited, pan, pizzas, garlic, breadrs,...     food\n",
       "167  [hey, loving, new, hike, awesome, stickers, op...    other\n",
       "168  [spl, bcom, classes, renowned, faculties, tax,...  finance\n",
       "169  [pls, reach, email, mrchrisc1outlookcom, immed...    other\n",
       "170  [pls, reach, email, mrchrisc1outlookcom, immed...    other\n",
       "171  [pest, control, winter, offer, make, home, pes...  fashion\n",
       "172  [thank, part, jio, family, stay, connected, la...  telecom\n",
       "173  [plan, jio, 8178390589, expires, today, servic...  finance\n",
       "174  [join, crash, course, engbstip, ecoafter, exce...    other\n",
       "175  [pearl, academy, invites, launch, school, medi...  telecom\n",
       "176  [main, tests15, live, classes35, video, lectur...  telecom\n",
       "177  [personal, loan, lowest, rate, preclose, charg...  fashion\n",
       "178  [looking, get, great, score, rank, jeemain18, ...    other\n",
       "179  [spot, admissions, forensic, science, cardiac,...    other\n",
       "180  [cbse, private, exam, 2018, forms, starting, c...    other\n",
       "181  [receive, offer, lottery, winnings, cheap, fun...  fashion\n",
       "182  [gokul, sent, blue, packet, expires, 59, mins,...  finance\n",
       "183  [cbse, private, exam, 2018, forms, starting, c...    other\n",
       "\n",
       "[7912 rows x 2 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "fashion     939\n",
       "finance    1371\n",
       "food        117\n",
       "health      332\n",
       "other      3354\n",
       "telecom    1306\n",
       "travel      493\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].groupby(df['Label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = df[df['Label']=='food'].reset_index().drop(['index'],axis=1)\n",
    "df_fashion = df[df['Label']=='fashion'].reset_index().drop(['index'],axis=1)\n",
    "df_finance = df[df['Label']=='finance'].reset_index().drop(['index'],axis=1)\n",
    "df_health = df[df['Label']=='health'].reset_index().drop(['index'],axis=1)\n",
    "df_other = df[df['Label']=='other'].reset_index().drop(['index'],axis=1)\n",
    "df_telecom = df[df['Label']=='telecom'].reset_index().drop(['index'],axis=1)\n",
    "df_travel = df[df['Label']=='travel'].reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = df_food[:117]\n",
    "df_fashion = df_fashion[:117]\n",
    "df_finance = df_finance[:117]\n",
    "df_health = df_health[:117]\n",
    "df_other = df_other[:117]\n",
    "df_telecom = df_telecom[:117]\n",
    "df_travel = df_travel[:117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalfunc(cols):\n",
    "    message = [st.stem(word) for word in cols]\n",
    "    return(' '.join(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Body'] = df_final['Body'].apply(finalfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_fashion,df_finance,df_food,df_health,df_telecom,df_travel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[monsoon, liveget, upto, 25medlife10mobikwikca...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[enjoy, saturdate, dominos, buy, mediumlarge, ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ek, behtar, lifestyle, ki, shuruaat, prateek,...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[get, axis, bank, zone, credit, card, free, li...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[haryana, govt, affordable, plots, deen, dayal...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body    Label\n",
       "0  [monsoon, liveget, upto, 25medlife10mobikwikca...   health\n",
       "1  [enjoy, saturdate, dominos, buy, mediumlarge, ...     food\n",
       "2  [ek, behtar, lifestyle, ki, shuruaat, prateek,...   travel\n",
       "3  [get, axis, bank, zone, credit, card, free, li...  finance\n",
       "4  [haryana, govt, affordable, plots, deen, dayal...  finance"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Body'] = df_final['Body'].apply(finalfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bodi thank domino privileg guest regist receiv...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bodi festiv offer book home golf citi readi mo...</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bodi pizza hut open baani squar sec 50 use cod...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bodi centrl govt aprvddelhi hous schemedwarka ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bodi centrl govt aprvddelhi hous schemeiidwark...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body    Label\n",
       "0  bodi thank domino privileg guest regist receiv...     food\n",
       "1  bodi festiv offer book home golf citi readi mo...  fashion\n",
       "2  bodi pizza hut open baani squar sec 50 use cod...     food\n",
       "3  bodi centrl govt aprvddelhi hous schemedwarka ...   travel\n",
       "4  bodi centrl govt aprvddelhi hous schemeiidwark...   travel"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final['Body']\n",
    "y = df_final['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     spl weekend offer free vitd tsh full check 73 ...\n",
       "507    sip purchas folio 949181666 hdfc balanc funddp...\n",
       "69     test intellig get surpris click http bajajhell...\n",
       "482    good bad rough smooth celebr everyday dominose...\n",
       "59     earn rs25000 annual also get lumpsum rs43 lac ...\n",
       "587        babe go food fast tha jaak khao khana fatafat\n",
       "513    deal week 60 health test rs999 diabtesthyroidc...\n",
       "579    last day book full health checkup rs 599 cbclf...\n",
       "667    post diwali health checkup rs2999 incl extend ...\n",
       "442    weight lossin rs3000 3 monthslimit offerloos 3...\n",
       "220    spl prediwali health offer buy 1 get 1 free fu...\n",
       "653    lose weight full stomach anjali mukerje health...\n",
       "497    get unlimit pan pizza garlic breadr 249 pizza ...\n",
       "509    tri offer swiggi order khidmat use code khidma...\n",
       "156    buy 1 get 1 free full checkup 2 rs 1299 50 tes...\n",
       "41     great opportun book plot divin citi krishna vr...\n",
       "170    get thyroid heart well packag 75 test thyroid ...\n",
       "540    1 commerci develop gurgaon offer food court 5 ...\n",
       "287    best luxuri villa godrej launch privat liftpar...\n",
       "696    tri new domino soft crust top tastier sauc che...\n",
       "180    stay vogu upto 80 amazon great indian festiv e...\n",
       "302    fav domino veg pizza got better soft crustmor ...\n",
       "195    full massag 799onli young femal therapist trea...\n",
       "37     rs349unlimit locstd call28gb 1gbdinsabhi hs pa...\n",
       "298    get unlimit pan pizza garlic breadr 249 pizza ...\n",
       "39     gift urself domino pizza occas that domino whe...\n",
       "528    hello chequ 015145 rs 6624 issu ac xxxx1359 re...\n",
       "33     domino pizza got better soft crust bigger top ...\n",
       "224    elig preapprov axi bank neo credit card appli ...\n",
       "108    dear custom 4 miss call 918279925985 last miss...\n",
       "                             ...                        \n",
       "390    dear rwa member spl prediwali health offer buy...\n",
       "27     lose weight full stomach anjali mukerje health...\n",
       "240    earn 50k per month rera approv retail shopsfoo...\n",
       "619    26th birthday bring extend shop hour shopper s...\n",
       "531    pre leas multiplex food court shopsrs40 lac le...\n",
       "612    join swiggi south delhi aur kamay 25000 rs tak...\n",
       "458    thank domino privileg guest regist receiv domi...\n",
       "331    attract interest rate ford aspir ford figo axi...\n",
       "655    full checkup 750 64 testssugar lft kft lipid t...\n",
       "72                                      ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ pizza khari\n",
       "63     abhi nahi kabhi nahi book 3 bhk cost 2 bhk noi...\n",
       "228    hey good news oneday approv credit card hurri ...\n",
       "694    get thyroid heart well packag 75 test thyroid ...\n",
       "19     rs349unlimit localstd call28gb 1gbdin28 din rs...\n",
       "383    diwali prebook gold coin kalyan jewel shopper ...\n",
       "345    dear rider welcom uber uber app design make bo...\n",
       "676    flat 50 pay rs999 full checkup rs1999 71test v...\n",
       "145    get flat 25 1st medicin order pharmeasi call 9...\n",
       "286    make home festiv readi hicar safegovt approv p...\n",
       "321    spl prediwali health offer buy 1 get 1 free fu...\n",
       "488    last day offer save upto 4530medlife15mobikwik...\n",
       "217    priy grahak aapk rs70 ke rchg ka benefit rs 70...\n",
       "656    strive help improv health commun work live opt...\n",
       "189    awesom sumita 240 point ushnakm claim reward r...\n",
       "289    diwali offer rate zabardast toofan bhari jawan...\n",
       "305    earn rs25000 annual also get lumpsum rs43 lac ...\n",
       "24     rs349unlimit localstd call28gb 1gbdin28 din rs...\n",
       "362    noida mein 1 bhk sirf 1375 lac 2 bhk sirf 22 l...\n",
       "31     chang wish see enjoy chang new domino get 20of...\n",
       "273    motap se mukti guarante ayurved capsul se mota...\n",
       "Name: Body, Length: 631, dtype: object"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = xyz.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 2590)\n"
     ]
    }
   ],
   "source": [
    "print(xxx.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Fitter=MultinomialNB().fit(xxx,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    fashion       0.95      0.92      0.93       100\n",
      "    finance       1.00      0.96      0.98       104\n",
      "       food       1.00      1.00      1.00       106\n",
      "     health       0.95      1.00      0.97       107\n",
      "    telecom       0.97      1.00      0.99       111\n",
      "     travel       1.00      0.98      0.99       103\n",
      "\n",
      "avg / total       0.98      0.98      0.98       631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predict = Fitter.predict(xxx)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,all_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    message = [word for word in nopunc.split() if word.lower() not in stopwords.words('English')]\n",
    "    message = [st.stem(word) for word in message]\n",
    "    return(' '.join(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    \n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x1a136c82f0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fashion', 'fashion', 'health', 'telecom', 'telecom', 'telecom',\n",
       "       'food', 'health', 'fashion', 'health', 'finance', 'fashion',\n",
       "       'telecom', 'fashion', 'food', 'food', 'telecom', 'telecom',\n",
       "       'finance', 'travel', 'travel', 'fashion', 'fashion', 'travel',\n",
       "       'travel', 'telecom', 'health', 'finance', 'fashion', 'health',\n",
       "       'fashion', 'health', 'health', 'food', 'travel', 'food', 'health',\n",
       "       'health', 'fashion', 'travel', 'fashion', 'fashion', 'finance',\n",
       "       'telecom', 'telecom', 'health', 'fashion', 'fashion', 'fashion',\n",
       "       'fashion', 'health', 'food', 'health', 'telecom', 'food',\n",
       "       'fashion', 'food', 'food', 'telecom', 'fashion', 'travel',\n",
       "       'travel', 'food', 'fashion', 'fashion', 'food', 'food', 'fashion',\n",
       "       'travel', 'food', 'finance'], dtype='<U7')"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    fashion       0.52      0.65      0.58        17\n",
      "    finance       0.80      0.31      0.44        13\n",
      "       food       0.69      0.82      0.75        11\n",
      "     health       0.58      0.70      0.64        10\n",
      "    telecom       0.36      0.67      0.47         6\n",
      "     travel       0.33      0.21      0.26        14\n",
      "\n",
      "avg / total       0.56      0.54      0.52        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fashion'], dtype='<U7')"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['buy tops and fashion sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelTry.pkl']"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline,'ModelTry.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
